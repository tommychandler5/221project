 1/1: print('hello class 2022')
 1/2: print('hello class 2023')
 1/3: print('hello class 2023 ~ we got this')
 1/4: print('hello class! ~ we got this')
 1/5: print('hello class! cheers to 2023 ~ we got this')
 1/6:
# add two integers
1+1000
 1/7:
# divide two integers to get a floating number
11/3
 1/8:
# multiply two integers
2 * 3
 1/9: 10/2
1/10:
10/2
9-4
1/11:
10/2
9-4
6+2
1/12: import math
1/13: math.sin(3)
1/14: math.sqrt(4)
1/15:
math.sin(3)
#name of the library - dot - brackets
1/16: math.sqrt(4)
1/17:
# variables, such as x here, contain values and their values can vary
x = 5
1/18:
# what is the value of x?
x
1/19:
# variables, such as x here, contain values and their values can vary
x = 50
1/20:
# what is the value of x?
x
1/21:
# variables, such as x here, contain values and their values can vary
x = 5
1/22:
# what is the value of x?
x
1/23:
# you can perform operations on variables, just like you can on two numbers
x + 3
1/24:
# what is the value of x now?
x
1/25:
# to update the value of a variable, you need to do an assignment again
x = x + 3
1/26:
# to update the value of a variable, you need to do an assignment again
x = x + 3
1/27:
# and now what is the value of x?
x
1/28:
# to update the value of a variable, you need to do an assignment again
x = x + 3
1/29:
# and now what is the value of x?
x
1/30:
# what is the value of x?
x
1/31:
# variables, such as x here, contain values and their values can vary
x = 5
1/32:
# what is the value of x?
x
1/33:
# you can perform operations on variables, just like you can on two numbers
x + 3
1/34:
# what is the value of x now?
x
1/35:
# to update the value of a variable, you need to do an assignment again
x = x + 3
1/36:
# and now what is the value of x?
x
1/37:
# create a new variable y from an operation on x
x = 5
y = x * 2
y
1/38:
# outputting values only displays the last thing output
# this is different from printing! it is kinda confusing!
x
y
1/39:
# use print to write some value(s) to the "console"
print(x)
print(y)
1/40:
# you can comma-separate values to print multiple values to the console on one line
# note that this syntax automatically adds a space between variables
print(x,y)
1/41:
# you can also print the result of an expression
print(x * y)
1/42:
# can you print and concatenate a number and a string?
print('x is ' + x)
1/43:
# the python print command can only concatenate values of the same type 
# so you need to convert numeric values to strings
print('x is: ' + str(x))
1/44:
z = x/(x+y)
print(z)
1/45:
temp_celsius = 3.0
#variables cannot have spaces
print(temp_celsius)
1/46: print('Temperature in Fahrenheit:',temp_celsius *(9/5) +32)
1/47: temp_celsius = 15.0
1/48: print('temperature in Celsius is now:', temp_celsius)
1/49: print('Temperature in Celsius:', 5/9 * (tempFahrenheit - 32))
1/50: tempFahrenheit = 9/5 * temp_celsius + 32
1/51: tempFahrenheit
1/52:
# ask ipython for it by using '?'
len?
1/53:
# click on a function or variable and press shift+tab 
print()
temp_celsius
tempFahrenheit
1/54:
# use tab-completion to fill in the rest of statements, functions, methods
tempFahrenheit
1/55:
# integers are whole numbers
type(125)
1/56:
# every variable has a data type, and they can be of any type
x = 125
type(x)
1/57:
# float is a floating point (aka decimal) number
some_rate = 4.3
type(some_rate)
1/58:
# strings are "strings" of characters
s = 'abc'
type(s)
1/59:
# a list is a collection of elements denoted by square brackets
# it knows it's a list because of those brackets
my_list = [1, 2, 3, 4]
my_list
1/60: type(my_list)
1/61:
# a dictionary is a collection of key:value pairs, denoted by curly braces
person = {'first_name':'Yoh', 'last_name':'Kawano','hobby':'soccer'}
person
1/62: type(person)
1/63:
# a dictionary can also be written like this for clarity, and for cases where there are many key:value pairs
person = {
            'first_name':'Yoh', 
            'last_name':'Kawano',
            'hobbies':'soccer'
}
1/64:
# now you try
# create a new dict variable containing the individual components of your home address
my_address = {
    'number':'4734',
    'street':'Farmdale Avenue',
    'city':'Los Angeles',
    'state':'California',
    'zipcode':'91602'
}
my_address
1/65:
# now you try
# create a new dict variable containing the individual components of your home address
my_address = {
    'City':'Los-Angeles',
    'State':'California',
    'Country':'USA'
}
my_address
1/66:
# now you try
# create a new dict variable containing the individual components of your home address
my_address = {
    'City':'Los Angeles',
    'State':'California',
    'Country':'USA'
}
my_address
1/67:
# now you try
# create a new dict variable containing the individual components of your home address
my_address = {
    'Street':'Farmdale Avenue',
    'City':'Los Angeles',
    'State':'California',
    'Country':'USA'
}
my_address
1/68:
# now you try
# create a new dict variable containing the individual components of your home address
my_address = {
    'Street':'Farmdale',
    'City':'Los Angeles',
    'State':'California',
    'Country':'USA'
}
my_address
1/69:
# now you try
# create a new dict variable containing the individual components of your home address
my_address = {
    'City':'Los Angeles',
    'State':'California',
    'Country':'USA'
}
my_address
1/70:
# some of the operators we saw earlier work on strings
city = 'Los Angeles'
sep = ', '
state = 'CA'
zip_code = '90095'

# you can "concatenate" strings with the + operator
location = city + sep + state + ' ' + zip_code
print(location)
1/71:
# error
state_county_FIPS = 06037
1/72:
# the FIPS code 06037 isn't actually a number, it's a string of numeric characters
# important to remember! FIPS codes aren't numeric, they are strings!
state_county_FIPS = '06037'
1/73:
# multiplying a string just duplicates it
state_county_FIPS * 3
1/74:
# you can get the nth element from an iterable object (like a string) with [n] indexing notation
# remember, in Python the index starts with zero not one
print(location)
location[0]
1/75:
print(location[0])
print(location[1])
print(location[2])
1/76:
# how many characters are in this string? use len function
len(location)
1/77:
# get a substring from some position up to but not including a second position
location[4:7]
1/78:
# get the first n characters from the string
location[:5]
1/79:
# get the characters from the string after the nth position
location[5:]
1/80:
# get the final n characters from the string
location[-5:]
1/81:
# you can replace characters in a string with the replace() method
location.replace('e', 'E')
1/82:
# now it's your turn
# create a new string from the 0th, 4th, and 6th characters in location
location[0,4,6:]
1/83:
# now it's your turn
# create a new string from the 0th, 4th, and 6th characters in location
location[0:]
1/84:
# now it's your turn
# create a new string from the 0th, 4th, and 6th characters in location
location[0:]
location[4:]
location[5:]
1/85:
# now it's your turn
# create a new string from the 0th, 4th, and 6th characters in location
location[0]
location[4]
location[5]
1/86: zip_code
1/87:
# you can convert between data types
type(zip_code)
1/88:
# convert the zip code string to an integer (notice what happens to the single quotes)
zip_code = int(zip_code)
zip_code
1/89: type(zip_code)
1/90:
# the math works better now
zip_code * 2
1/91:
# the int function won't convert a string that looks like a floating point number
rent_str = '2500.00'
rent_int = int(rent_str)
1/92:
# the int function won't convert a string that looks like a floating point number
rent_str = '2500'
rent_int = int(rent_str)
1/93:
# the int function won't convert a string that looks like a floating point number
rent_str = '2500.00'
rent_int = int(rent_str)
1/94:
# but you can daisy-chain functions together to convert the string to a float then to an int
# the inner function executes then passes its value to the outer function
rent_int = int(float(rent_str))
rent_int
1/95:
# now it's your turn
# create a new string from the 0th, 4th, and 6th characters in location
print(location[0]+location[4]+location[6])
1/96:
# you cannot concatenate a string and a number
city = 'Los Angeles '
zip_code = 90089
city + zip_code
1/97:
# so convert the number first, then concatenate
city + str(zip_code)
1/98:
# this is a list
my_list = [2, 4, 6, 8]
1/99:
# how many elements are in this list?
len(my_list)
1/100:
# get the zero-th element in a list
my_list[0]
1/101:
# you can update elements in a list because it is mutable
my_list[2] = 100
my_list
1/102:
# add a new element with the append() method
# lists can hold elements of varying data types
my_list.append('hello')
my_list
1/103:
# import folium, a leaflet python library
import folium

# create a list of lat/lon pair for UCLA
ucla = [34.0721237,-118.4440685]
m = folium.Map(location=ucla, zoom_start=15)
m
1/104:
# import folium, a leaflet python library
import folium

# create a list of lat/lon pair for UCLA
ucla = [34.0721237,-118.4440685]
m = folium.Map(location=ucla, zoom_start=43)
m
1/105:
# import folium, a leaflet python library
import folium

# create a list of lat/lon pair for UCLA
ucla = [34.0721237,-118.4440685]
m = folium.Map(location=ucla, zoom_start=2)
m
1/106:
# import folium, a leaflet python library
import folium

# create a list of lat/lon pair for UCLA
ucla = [34.0721237,-118.4440685]
m = folium.Map(location=ucla, zoom_start=8)
m
1/107:
# import folium, a leaflet python library
import folium

# create a list of lat/lon pair for UCLA
ucla = [34.0721237,-118.4440685]
m = folium.Map(location=ucla, zoom_start=15)
m
 2/1:
import pandas as pd
import geopandas as gpd
 2/2:
# read and add shapefile to notebook
metro = gpd.read_file('data/Stations_All_0316.zip')
 2/3:
# read and add shapefile to notebook
metro = gpd.read_file('data/Stations_All_0316.zip')
 2/4:
# what's the data type?
type(metro)
 2/5:
# what does the data look like? 
metro.head()
 2/6:
# what does the data look like? 
metro.head(10)
 2/7:
# try tail()
metro.tail(1)
 2/8:
# try sample()
metro.sample(2)
 2/9:
# try sample()
metro.sample(2)
2/10:
# try sample()
metro.sample(2)
2/11:
# try sample()
metro.sample(2)
2/12: metro.dtypes
2/13:
# dataframe info
metro.info()
2/14:
# how many rows and columns?
metro.shape
2/15:
# what are the columns?
metro.columns.to_list()
2/16:
# column name in brackets
# single column
metro['LINE'].sample(5)
2/17:
# another way
metro.LINE.sample(5)
2/18: metro['LINE'].value_counts()
2/19:
# save it as a variable
line_count = metro['LINE'].value_counts()
line_count
2/20:
# what data type is line_count?
type(line_count)
2/21:
# let's convert the series into a dataframe
line_count = line_count.reset_index()
line_count
2/22: type(line_count)
2/23:
# current columns as a list
line_count.columns.to_list()
2/24: line_count.columns = ['line', 'count']
2/25: line_count
2/26: line_count.plot()
2/27:
# give it additional arguments
line_count.plot.bar(x = 'line', y = 'count', title = 'Number of stops per metro line')
2/28:
# output the original data's info
metro.info()
2/29:
# show a dataframe with a subset of columns
metro[['LINE','LINENUM','STATION','LAT','LONG','geometry']]
2/30:
# list of desired column names
desired_columns = ['LINE','LINENUM','STATION','LAT','LONG','geometry']

# subset based on desired columns
metro[desired_columns].sample(5)
2/31: metro.head()
2/32:
metro_trimmed = metro[desired_columns].copy()
metro_trimmed
2/33:
metro_trimmed = metro[desired_columns].copy()
metro
2/34:
metro_trimmed = metro[desired_columns].copy()
metro_trimmed
2/35: metro_trimmed[metro_trimmed.LINE == 'EXPO']
2/36:
# another way .loc
metro_trimmed.loc[metro_trimmed['LINE'] == 'Red']
2/37:
# another way .query
metro_trimmed.query("LINE == 'EXPO'")
2/38:
# try it yourself. Query the dataframe for other properties of interest
metro_trimmed.query("LINE == 'GOLD'")
2/39:
# try it yourself. Query the dataframe for other properties of interest
metro_trimmed.query("LINE == 'Red'")
2/40: metro_trimmed.plot()
2/41: metro_trimmed.geometry
2/42:
metro_trimmed.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'LINE',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
2/43:
# default folium map
m = folium.Map()
m
2/44:
# default folium map
m = folium.Map()
m
2/45: import folium
2/46:
# default folium map
m = folium.Map()
m
2/47:
# average latitude
latitude = metro_trimmed.LAT.mean()
latitude
2/48:
# average longitude
longitude = metro_trimmed.LONG.mean()
longitude
2/49:
# complete this code so that the map will show up 
# centered based on the average lat/lon calculated above
# adjust the zoom level accordingly
m = folium.Map(location=[latitude,longitude])
m
2/50:
# first, note how to loop through a dataframe:
for index, row in metro_trimmed.iterrows():
    print(row.STATION, row.LAT, row.LONG)
2/51:
for index, row in metro_trimmed.iterrows():
    # add folium marker code
    folium.Marker([row.LAT, row.LONG], popup=row.STATION, tooltip=row.STATION).add_to(m)
m
2/52:
# add a new column
metro_trimmed['color'] = ''
2/53: metro_trimmed.head()
2/54:
# find unique values in the LINE column
metro_trimmed.LINE.unique()
2/55:
# display rows that match a query
metro_trimmed.loc[metro_trimmed['LINE'] == 'EXPO']
2/56: metro_trimmed.loc[metro_trimmed['LINE'] == 'EXPO', 'color'] = 'orange'
2/57:
# check your work
metro_trimmed.loc[metro_trimmed['LINE'] == 'EXPO']
2/58:
# Add a color value to each of the following lines: 'Blue', 'Blue/EXPO', 'EXPO', 'Red', 'Red/Purple', 'Purple', 'Green', 'Gold'
# The first one is done for you:
metro_trimmed.loc[metro_trimmed['LINE'] == 'Blue', 'color'] = 'blue'
metro_trimmed.loc[metro_trimmed['LINE'] == 'Blue/EXPO', 'color'] = 'darkblue'
metro_trimmed.loc[metro_trimmed['LINE'] == 'Red', 'color'] = 'red'
metro_trimmed.loc[metro_trimmed['LINE'] == 'Red/Purple', 'color'] = 'darkpurple'
metro_trimmed.loc[metro_trimmed['LINE'] == 'Purple', 'color'] = 'purple'
metro_trimmed.loc[metro_trimmed['LINE'] == 'Green', 'color'] = 'green'
metro_trimmed.loc[metro_trimmed['LINE'] == 'Gold', 'color'] = 'beige'
2/59: metro_trimmed.sample(5)
2/60:
# reset the map (you need to do this to erase previous layers)
m = folium.Map(location=[latitude,longitude], tiles='Stamen Terrain', zoom_start=10)
2/61:
# add the stations with color icons
for index, row in metro_trimmed.iterrows():
    tooltip_text = row.LINE + ' Line: ' + row.STATION
    folium.Marker(
        [row.LAT,row.LONG], 
        popup=row.STATION, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
2/62:
# save the interactive maps as an html file
m.save('metro.html')
2/63:
# save the interactive maps as an html file
m.save('metro.html')
 4/1: station = 'Westwood / Rancho Park'
 4/2: linenum = 806
 4/3: stopnum = 80134
 4/4: lat = 34.0368
 4/5: long = -118.425
 4/6: type(station)
 4/7: type(linenum)
 4/8: type(lat)
 4/9: sum(station+linenum)
 6/1:
# alternatively, you can use a comma! 
# confusing, but do you see the difference?
print('x is:', x)
 6/2:
# alternatively, you can use a comma! 
# confusing, but do you see the difference?
print('x is:', x)
 6/3: print('hello class! cheers to 2023 ~ we got this')
 6/4:
# this is a comment. the python interpreter ignores it. anything with a ahastag is a comment!
# comments are just notes for humans to read to help understand the code
# best practice: add a comment for every couple lines of code to explain what's going on and why
# you'd be amazed at how quickly you forget your code's logic (at least i always do)

print('hello world')
 6/5:
# add two integers
1+1000
 6/6:
# divide two integers to get a floating number
11/3
 6/7:
# multiply two integers
2 * 3
 6/8:
10/2
9-4
6+2
 6/9: import math
6/10:
math.sin(3)
#name of the library - dot - brackets
6/11: math.sqrt(4)
6/12: math.pi
6/13:
# variables, such as x here, contain values and their values can vary
x = 5
6/14:
# what is the value of x?
x
6/15:
# you can perform operations on variables, just like you can on two numbers
x + 3
6/16:
# you can perform operations on variables, just like you can on two numbers
sum(x + 3)
6/17:
# you can perform operations on variables, just like you can on two numbers
x + 3
6/18: sum(6+2)
6/19: 6+2
6/20:
# what is the value of x now?
x
6/21:
# to update the value of a variable, you need to do an assignment again
x = x + 3
6/22:
# and now what is the value of x?
x
6/23:
# create a new variable y from an operation on x
x = 5
y = x * 2
y
6/24:
# outputting values only displays the last thing output
# this is different from printing! it is kinda confusing!
x
y
6/25:
# use print to write some value(s) to the "console"
print(x)
print(y)
6/26:
# you can comma-separate values to print multiple values to the console on one line
# note that this syntax automatically adds a space between variables
print(x,y)
6/27:
# you can also print the result of an expression
print(x * y)
6/28:
# can you print and concatenate a number and a string?
print('x is ' + x)
6/29:
# can you print and concatenate a number and a string?
print('x is 5' + x)
6/30:
# the python print command can only concatenate values of the same type 
# so you need to convert numeric values to strings
print('x is: ' + str(x))
4/10: print('station ' + str(linenum))
4/11: print('station ' + str(linenum))
4/12: linenum_str = str(linenum)
4/13: type(linenum_str)
4/14: linenum_str
4/15: station_name_and_id = station + ": " + str(linenum)
4/16: print(station_name_and_id)
4/17: print(station + linenum_str)
4/18: print(station_name_and_id)
4/19: station_names = ['Pico', 'Culver City', 'Westwood / Rancho Park', 'Downtown Santa Monica']
4/20: print(station_names)
4/21: type(station_names)
4/22: print(station_names[1])
4/23: print(station_names[0])
4/24: len(station__names)
4/25: len(station_names)
4/26: print(station_names[4])
4/27: print(station_names)
4/28: print(station_names[-1])
4/29: print(station_names[-4])
4/30: print(station_names[-5])
4/31:
station_names[1] = 'Palms'
print(station_names)
4/32:
station_westwood_rancho = [station, linenum, lat, long, linenum]
print(station_westwood_rancho)
4/33: type(station_westwood_rancho)
4/34: type(station_westwood_rancho[0])    # The station name
4/35: type(station_westwood_rancho[1])    # The linenum
4/36: type(station_westwood_rancho[2])    # The station latitude
4/37: print(station_names)
4/38: del station_names[0]
4/39: print(station_names)
4/40:
station_names.append('Pico')
station_names.append('Farmdale')
4/41: print(station_names)
4/42: station_names
4/43: station_names.count('Pico')    # The count method counts the number of occurences of a value
4/44: station_names.index('Pico')    # The index method gives the index value of an item in a list
4/45: station_names.sort()   # Notice no output here...
4/46: print(station_names)
4/47:
# loop through a list
for station in station_names:
    print(station)
4/48:
for station in station_names:
    print('Expo line station: ' + station)
4/49:
# enumerate lets you loop though a list and count along
for count, station in enumerate(station_names):
    print(count, station)
 9/1:
# read and add shapefile to notebook
metro = gpd.read_file('data/Stations_All_0316.zip')
 9/2:
import pandas as pd
import geopandas as gpd
 9/3:
# read and add shapefile to notebook
metro = gpd.read_file('data/Stations_All_0316.zip')
 9/4:
# what's the data type?
type(metro)
 9/5:
import pandas as pd
import geopandas as gpd
 9/6:
# read and add shapefile to notebook
metro = gpd.read_file('data/Stations_All_0316.zip')
 9/7:
# what's the data type?
type(metro)
 9/8:
# what's the data type?
type(metro)
 9/9:
# what does the data look like? 
metro.head(10)
9/10:
# what does the data look like? 
metro.head()
9/11:
# try tail()
metro.tail(1)
9/12:
# try sample()
metro.sample(2)
9/13: metro.dtypes
9/14:
# dataframe info
metro.info()
9/15:
# how many rows and columns?
metro.shape
9/16:
# what are the columns?
metro.columns.to_list()
 8/1: ##Week 1 Assignment
 8/2: # Week 1 Assignment
 8/3: In this assignment, I'll explore a dataset from OpenSF that examines historic maps of redlining in San Francisco
 8/4: In this assignment, I will explore a dataset from OpenSF that examines historic maps of redlining in San Francisco
 8/5: In this assignment I will explore a dataset from OpenSF that examines historic maps of redlining in San Francisco
 8/6: #In this assignment I will explore a dataset from OpenSF that examines historic maps of redlining in San Francisco
 8/7:
# I will now go ahead and import the libraries that were used in the example
import pandas as pd
import geopandas as gpd
 8/8:
# Now its time to add my shapefile into this notebook
redliningmap = gpd.read_file('CASanFrancisco_RedliningMaps.zip')
 8/9:
# Now its time to add my shapefile into this notebook
redliningmap = gpd.read_file('data/CASanFrancisco_RedliningMaps.zip')
8/10: type(redlining)
8/11: type(redliningmap)
8/12: redliningmap.head()
8/13: redliningmap.sample(2)
8/14: redliningmap.dtypes
8/15: redliningmap.shape
8/16: redlining.columns.to_list()
8/17: redliningmaps.columns.to_list()
8/18: redliningmap.columns.to_list()
8/19: redliningmap['holc_grade'].sample(5)
8/20: redliningmap.info()
8/21: redliningmap[redliningmap.holc_grade == 'A']
8/22: redliningmap.plot()
8/23: print(screaming)
8/24: print('screaming')
8/25:
metro_trimmed.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'holc_grade',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/26:
redliningmap.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'holc_grade',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/27: ## In this assignment I will explore a dataset from OpenSF that examines historic maps of redlining in San Francisco
8/28: import folium
8/29:
# default folium map
m = folium.Map()
m
8/30:
# average latitude
latitude = redliningmap.LAT.mean()
latitude
8/31:
# average latitude
latitude = redliningmap.geometry.mean()
latitude
8/32:
m = folium.Map(location=[37.7749, 122.4194])
m
8/33:
m = folium.Map(location=[37.7749, -122.4194])
m
8/34:
m = folium.Map(location=[37.7749, -122.4194])
m
8/35: m = folium.Map(location=[latitude,longitude], tiles='Stamen Terrain', zoom_start=10)
8/36: m = folium.Map(location=[37.7749, -122.4194], tiles='Stamen Terrain', zoom_start=10)
8/37: m = folium.Map(location=[37.7749, -122.4194], zoom_start=10)
8/38: m = folium.Map(location=[37.7749, -122.4194], zoom_start=10)
8/39: m = folium.Map(location=[37.7749, -122.4194], tiles='Stamen Terrain', zoom_start=10)
8/40: m
8/41: m = folium.Map(location=[37.7749, -122.4194], tiles='Stamen Terrain', zoom_start=10, redliningmap)
8/42:
m = folium.Map(location=[37.7749, -122.4194], tiles='Stamen Terrain', zoom_start=10)
redliningmap.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'holc_grade',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
) 
m
8/43:
# I will now go ahead and import the libraries that were used in the example
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
8/44:
# Now its time to add my shapefile into this notebook
redliningmap = gpd.read_file('data/CASanFrancisco_RedliningMaps.zip')
8/45: df.head()
8/46: redliningmap.head()
8/47: redliningmap.tyoe()
8/48: redliningmap.type()
8/49: redliningmap.dtypes
8/50:
redliningmap.plot(figsize=(6,6))
plt.show()
8/51:
redliningmap.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'holc_id',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/52:
redliningmap.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'holc_grade',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/53:
m = folium.Map(location=[37.7749, -122.4194], zoom_start=15, tiles='CartoDB positron')
m
8/54:
m = folium.Map(location=[37.7749, -122.4194], zoom_start=12, tiles='CartoDB positron')
m
8/55:
for _, r in redliningmap.iterrows():
    sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)
    geo_j = sim_geo.to_json()
    geo_j = folium.GeoJson(data=geo_j,
                           style_function=lambda x: {'fillColor': 'orange'})
    folium.Popup(r['holc_grade']).add_to(geo_j)
    geo_j.add_to(m)
m
8/56:
for _, r in redliningmap.iterrows():
    sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)
    geo_j = sim_geo.to_json()
    geo_j = folium.GeoJson(data=geo_j,
                           style_function=lambda x: {'fillColor': 'blue'})
    folium.Popup(r['holc_grade']).add_to(geo_j)
    geo_j.add_to(m)
m
8/57:
# add a new column
redliningmap['color'] = ''
8/58: redliningmap.head()
8/59: redliningmap.holc_grade.unique()
8/60: redliningmap.loc[redliningmap['holc_grade'] == 'A']
8/61: redliningmap.loc[redliningmap['holc_grade'] == 'A', 'color'] = 'green'
8/62: redliningmap.loc[redliningmap['holc_grade'] == 'A'
8/63: redliningmap.loc[redliningmap['holc_grade'] == 'A']
8/64:
redliningmap.loc[redliningmap['holc_grade'] == 'B', 'color'] = 'blue'
redliningmap.loc[redliningmap['holc_grade'] == 'C', 'color'] = 'yellow'
redliningmap.loc[redliningmap['holc_grade'] == 'D', 'color'] = 'red'
8/65: redliningmap.sample(5)
8/66:
redliningmap.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'holc_grade',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/67: m=folium.Map(location=[[37.7749, -122.4194], zoom_start=12, tiles='CartoDB positron')
8/68: m=folium.Map(location=[[37.7749, -122.4194], zoom_start=12, tiles='CartoDB positron'])
8/69: m=folium.Map(location=[[37.7749, -122.4194], zoom_start=12, tiles='CartoDB positron')
8/70: m=folium.Map(location=[37.7749, -122.4194], zoom_start=12, tiles='CartoDB positron')
8/71:
redliningmap.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'holc_grade',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/72:
redliningmap.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'color',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/73:
redliningmap.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'holc_grade',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/74: m=folium.Map(location=[37.7749, -122.4194], zoom_start=12, tiles='CartoDB positron')
8/75:
for index, row in redliningmap.iterrows():
    tooltip_text = row.geometry
    folium.Marker(
        [row.geometry], 
        popup=row.holc_grade, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
8/76:
redliningmap.plot(figsize=(6,6))
plt.show()
8/77: ## In this assignment I will explore a dataset from the Mapping Inequality Project that examines historic maps of redlining in San Francisco
8/78: ## Week 1 Assignment
8/79: print('In this assignment I will explore a dataset from the Mapping Inequality Project that examines historic maps of redlining in San Francisco')
8/80: redliningmap.head(3)
8/81: redliningmap.sample(3)
8/82: redliningmap['holc_grade'].sample(5)
8/83: redliningmap.loc[redliningmap['holc_grade']
8/84: redliningmap
8/85:
# default folium map
m = folium.Map()
m
8/86:
m = folium.Map(location=[37.7749, -122.4194], zoom_start=12, tiles='CartoDB positron')
m
8/87:
for _, r in redliningmap.iterrows():
    sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)
    geo_j = sim_geo.to_json()
    geo_j = folium.GeoJson(data=geo_j,
                           style_function=lambda x: {'fillColor': 'blue'})
    folium.Popup(r['holc_grade']).add_to(geo_j)
    geo_j.add_to(m)
m
8/88:
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
8/89: bikes = gpd.read_file('data/LABikesLanes.zip')
8/90:
import pandas as pd
import geopandas as gpd
8/91: bikes=gpd.read_file('data/LABikeLanes.zip')
8/92: redliningmap.dtypes
8/93: bikes.dtypes
8/94: type(bikes)
8/95: bikes.head()
8/96: bikes.shape
8/97: bikes.plot
8/98: bikes.plot()
8/99:
bikes.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'geometry',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/100:
bikes.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
8/101:
import pandas as pd
import geopandas as gpd
8/102: art = gpd.read_file('data/Civic Art Collection.zip')
8/103: type(art)
8/104: art.head()
8/105: art.dtypes
8/106: art.shape
8/107: art['medium'].value_counts()
8/108: art['medium'].value_counts(3)
8/109: art['medium'].value_counts()
8/110: art[art.zip_code == '94117']
8/111: art.plot()
8/112:
art.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'supervisor',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
11/1: redliningmap['holc_grade'].value_counts()[A]
11/2:
# I will now go ahead and import the libraries that were used in the example
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
11/3:
# Now its time to add my shapefile into this notebook
redliningmap = gpd.read_file('data/CASanFrancisco_RedliningMaps.zip')
11/4:
# Now its time to add my shapefile into this notebook
redliningmap = gpd.read_file('data/CASanFrancisco_RedliningMaps.zip')
11/5: redliningmap.loc[redliningmap['holc_grade'] == 'A']
11/6: redliningmap['holc_grade'].value_counts()[A]
11/7: print(redliningmap['holc_grade'].value_counts()['A'])
11/8: print(redliningmap['holc_grade'].value_counts()['B'])
11/9: print(redliningmap['holc_grade'].value_counts()['C'])
11/10: print(redliningmap['holc_grade'].value_counts()['D'])
11/11: metro.info()
11/12: art.info()
11/13: art.info()
11/14:
import pandas as pd
import geopandas as gpd
11/15: art = gpd.read_file('data/Civic Art Collection.zip')
11/16: art.info()
11/17:
# list of desired column names
desired_columns = ['artist','display_ti','facility', 'medium','zip_code', 'latitude','longitude','supervisor', 'geometry']
11/18:
# subset based on desired columns
art[desired_columns].sample(5)
15/1:
## Week 1 Assignment
Following our Python bootcamp last week (was it boring? exhilerating? a bit of both?), let's put that pro
15/2:
## Week 1 Assignment
Following our Python bootcamp last week
15/3: ## Week 1 Assignment
15/4: print('In this assignment I will explore a dataset from the Mapping Inequality Project that examines historic maps of redlining in San Francisco')
15/5:
### Execution Modes
* **Edit mode**:  changing the content within a cell
  
  
* **Command mode**:  performing actions on the notebook as a whole
22/1:
import pandas as pd
import geopandas as gpd
22/2:
# read and adding my shapefile to notebook
art = gpd.read_file('data/Civic Art Collection.zip')
22/3:
# read and adding my shapefile to notebook
art = gpd.read_file('data/Civic Art Collection.zip')
22/4:
# what's the data type?
type(art)
22/5:
# what exactly does my data look like? pulling a sample of 3 random rows 
art.head()
22/6:
# what exactly does my data look like? pulling a sample of 3 random rows 
art.head(3)
22/7: art.dypes
22/8: art.dtypes
22/9: art.info()
22/10: art.shape
22/11:
# column name in brackets
# single column
art['medium'].sample(3)
22/12: art['medium'].value_counts()
22/13: art['medium'].value_counts(3)
22/14: art['medium'].value_counts()
22/15:
# output the original data's info again
art.info()
22/16:
# now let's show a dataframe with a specific subset of columns
metro[['artist', 'display_ti', 'medium', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']]
22/17:
# now let's show a dataframe with a specific subset of columns
art[['artist', 'display_ti', 'medium', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']]
22/18:
art.plot(
            figsize=(20,12),   #size of the plot (a bit bigger than the default)
            column = 'zip_code',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
29/1:
import pandas as pd
import geopandas as gpd
29/2:
# read and adding my shapefile to notebook
art = gpd.read_file('data/Civic Art Collection.zip')
29/3:
# read and adding my shapefile to notebook
art = gpd.read_file('data/Civic Art Collection.zip')
29/4:
# what's the data type?
type(art)
29/5:
# what exactly does my data look like? 
art.head(3)
29/6: art.dtypes
29/7: art.info()
29/8: art.shape
29/9:
# column name in brackets
# single column
art['medium'].sample(3)
29/10:
# column name in brackets
# single column
art['medium'].sample(3)
29/11:
# column name in brackets
# single column
art['medium'].sample(3)
29/12:
# column name in brackets
# single column
art['medium'].sample(3)
29/13: art['medium'].value_counts()
29/14:
# output the original data's info again
art.info()
29/15:
# now let's show a dataframe with a specific subset of columns
art[['artist', 'display_ti', 'medium', 'media_supp', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']]
29/16:
# create and define a list of desired column names
desired_columns = ['artist', 'display_ti', 'medium', 'media_supp', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']

# subset based on desired columns
art[desired_columns].sample(3)
29/17:
art_trim = metro[desired_columns].copy()
art_trim
29/18:
art_trim = mart[desired_columns].copy()
art_trim
29/19:
art_trim = art[desired_columns].copy()
art_trim
29/20: art_trim[art_trim.medium == 'bronze']
29/21: art_trim[art_trim.supervisor == '05']
29/22: art_trim.plot()
29/23:
art_trim.plot(
            figsize=(18,10),   #size of the plot 
            column = 'zip_code',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
29/24:
art_trim.plot(
            figsize=(20,10),   #size of the plot 
            column = 'zip_code',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
29/25:
art_trim.plot(
            figsize=(14,12),   #size of the plot 
            column = 'zip_code',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
29/26:
art_trim.plot(
            figsize=(14,12),   #size of the plot 
            column = 'supervisor',   # column that defines the color of the dots
            legend = True,     # add a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this puts the legend to the side
)
29/27: import folium
29/28:
# default folium map
m = folium.Map()
m
29/29:
# average latitude
latitude = art_trim.latitude.mean()
latitude
29/30:
# average longitude
longitude = art_trim.longitude.mean()
longitude
29/31:
# centered based on the average lat/lon calculated above
# adjust the zoom level accordingly
m = folium.Map(location=[34.01187554166666, -118.24713253124999])
m
29/32:
# centered based on the average lat/lon calculated above
# adjust the zoom level accordingly
m = folium.Map(location=[34.01187554166666, -118.24713253124999])
m
29/33:
# centered based on the average lat/lon calculated above
# adjust the zoom level accordingly
m = folium.Map(location=[37.741717888974996, -118.24713253124999])
m
32/1:
# complete this code so that the map will show up 
# centered based on the average lat/lon calculated above
# adjust the zoom level accordingly
m = folium.Map(location=[latitude,longitude])
m
32/2: import folium
32/3:
# default folium map
m = folium.Map()
m
32/4:
# average latitude
latitude = metro_trimmed.LAT.mean()
latitude
29/34:
# centered based on the average lat/lon calculated above
# adjust the zoom level accordingly
m = folium.Map(location=[37.741717888974996, -118.24713253124999])
m
29/35:
# centered based on the average lat/lon calculated above
# adjust the zoom level accordingly
m = folium.Map(location=[37.741717888974996, -122.42401938244218])
m
29/36:
# first, note how to loop through a dataframe:
for index, row in art_trim.iterrows():
    print(row.display_ti, row.latitude, row.longitude)
29/37:
for index, row in art_trim.iterrows():
    # add folium marker code
    folium.Marker([row.latitude, row.longitude], popup=row.display_ti, tooltip=row.display_ti).add_to(m)
m
29/38: Great! But can I color code the markers according to the district in which they reside in?
32/5:
# add a new column
metro_trimmed['color'] = ''
29/39:
# lets add a new column
art_trim['color'] = ''
29/40: art_trim.head()
29/41:
# find unique values in the LINE column
art_trim.zip__code.unique()
29/42:
# find unique values in the LINE column
art_trim.zip_code.unique()
29/43:
# find unique values in the LINE column
art_trim.supervisor.unique()
29/44: art_trim.head(3)
29/45: art_trim.head(5)
29/46: art_trim.head(8)
29/47: art_trim.head(3)
29/48:
# Add a color value to each of the eleven districts, plus a twelth for ones categorized as 'none' 
art_trim.loc[art_trim['supervisor'] == 'None', 'color'] = 'red'
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
29/49:
# Add a color value to each of the eleven districts, plus a twelth for ones categorized as 'none' 
art_trim.loc[art_trim['supervisor'] == 'None', 'color'] = 'red'
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
art_trim.loc[art_trim['supervisor'] == '03', 'color'] = 'purple'
art_trim.loc[art_trim['supervisor'] == '04', 'color'] = 'orange'
art_trim.loc[art_trim['supervisor'] == '05', 'color'] = 'beige'
art_trim.loc[art_trim['supervisor'] == '06', 'color'] = 'darkblue'
art_trim.loc[art_trim['supervisor'] == '07', 'color'] = 'white'
art_trim.loc[art_trim['supervisor'] == '08', 'color'] = 'pink'
art_trim.loc[art_trim['supervisor'] == '09', 'color'] = 'gray'
art_trim.loc[art_trim['supervisor'] == '10', 'color'] = 'lightgreen'
art_trim.loc[art_trim['supervisor'] == '11', 'color'] = 'darkred'
29/50: art_trim.sample(3)
29/51:
# Add a color value to each of the eleven districts, plus a twelth for ones categorized as 'none' 
art_trim.loc[art_trim['supervisor'] == 'none', 'color'] = 'red'
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
art_trim.loc[art_trim['supervisor'] == '03', 'color'] = 'purple'
art_trim.loc[art_trim['supervisor'] == '04', 'color'] = 'orange'
art_trim.loc[art_trim['supervisor'] == '05', 'color'] = 'beige'
art_trim.loc[art_trim['supervisor'] == '06', 'color'] = 'darkblue'
art_trim.loc[art_trim['supervisor'] == '07', 'color'] = 'white'
art_trim.loc[art_trim['supervisor'] == '08', 'color'] = 'pink'
art_trim.loc[art_trim['supervisor'] == '09', 'color'] = 'gray'
art_trim.loc[art_trim['supervisor'] == '10', 'color'] = 'lightgreen'
art_trim.loc[art_trim['supervisor'] == '11', 'color'] = 'darkred'
29/52:
# let's reset the map and get ready to add the color-coded icons
m = folium.Map(location=[latitude,longitude], tiles='CartoDB positron', zoom_start=10)
29/53:
# alright here we go: lets finally add the color-coded icons
for index, row in art_trim.iterrows():
    tooltip_text = row.supervisor + ' supervisor: ' + row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
29/54:
# alright here we go: lets finally add the color-coded icons
for index, row in art_trim.iterrows():
    tooltip_text = row.supervisor + ' Supervisor: ' + row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
29/55:
# Add a color value to each of the eleven districts, plus a twelth for ones categorized as 'none' 
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
art_trim.loc[art_trim['supervisor'] == '03', 'color'] = 'purple'
art_trim.loc[art_trim['supervisor'] == '04', 'color'] = 'orange'
art_trim.loc[art_trim['supervisor'] == '05', 'color'] = 'beige'
art_trim.loc[art_trim['supervisor'] == '06', 'color'] = 'darkblue'
art_trim.loc[art_trim['supervisor'] == '07', 'color'] = 'white'
art_trim.loc[art_trim['supervisor'] == '08', 'color'] = 'pink'
art_trim.loc[art_trim['supervisor'] == '09', 'color'] = 'gray'
art_trim.loc[art_trim['supervisor'] == '10', 'color'] = 'lightgreen'
art_trim.loc[art_trim['supervisor'] == '11', 'color'] = 'darkred'
29/56: art_trim.sample(3)
29/57:
# let's reset the map and get ready to add the color-coded icons
m = folium.Map(location=[latitude,longitude], tiles='CartoDB positron', zoom_start=10)
29/58:
# alright here we go: lets finally add the color-coded icons
for index, row in art_trim.iterrows():
    tooltip_text = row.supervisor + ' Supervisor: ' + row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
29/59:
# alright here we go: lets finally add the color-coded icons
for index, row in art_trim.iterrows():
    tooltip_text = row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
29/60:
# alright here we go: lets finally add the color-coded icons
for index, row in art_trim.iterrows():
    tooltip_text = row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
29/61:
# let's reset the map and get ready to add the color-coded icons
m = folium.Map(location=[latitude,longitude], tiles='CartoDB positron', zoom_start=12)
29/62:
# alright here we go: lets finally add the color-coded icons
for index, row in art_trim.iterrows():
    tooltip_text = row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
29/63:
# Add a color value to each of the eleven districts, plus a twelth for ones categorized as 'none' 
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
art_trim.loc[art_trim['supervisor'] == '03', 'color'] = 'purple'
art_trim.loc[art_trim['supervisor'] == '04', 'color'] = 'orange'
art_trim.loc[art_trim['supervisor'] == '05', 'color'] = 'beige'
art_trim.loc[art_trim['supervisor'] == '06', 'color'] = 'darkblue'
art_trim.loc[art_trim['supervisor'] == '07', 'color'] = 'cadetblue'
art_trim.loc[art_trim['supervisor'] == '08', 'color'] = 'pink'
art_trim.loc[art_trim['supervisor'] == '09', 'color'] = 'gray'
art_trim.loc[art_trim['supervisor'] == '10', 'color'] = 'lightgreen'
art_trim.loc[art_trim['supervisor'] == '11', 'color'] = 'darkred'
29/64:
# let's reset the map and get ready to add the color-coded icons
m = folium.Map(location=[latitude,longitude], tiles='CartoDB positron', zoom_start=12)
29/65:
# alright here we go: lets finally add the color-coded icons
for index, row in art_trim.iterrows():
    tooltip_text = row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
29/66:
# Add a color value to each of the eleven districts, plus a twelth for ones categorized as 'none' 
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
art_trim.loc[art_trim['supervisor'] == '03', 'color'] = 'purple'
art_trim.loc[art_trim['supervisor'] == '04', 'color'] = 'orange'
art_trim.loc[art_trim['supervisor'] == '05', 'color'] = 'beige'
art_trim.loc[art_trim['supervisor'] == '06', 'color'] = 'darkblue'
art_trim.loc[art_trim['supervisor'] == '07', 'color'] = 'cadetblue'
art_trim.loc[art_trim['supervisor'] == '08', 'color'] = 'pink'
art_trim.loc[art_trim['supervisor'] == '09', 'color'] = 'gray'
art_trim.loc[art_trim['supervisor'] == '10', 'color'] = 'lightgreen'
art_trim.loc[art_trim['supervisor'] == '11', 'color'] = 'red'
29/67:
# alright here we go: lets finally add the color-coded icons
for index, row in art_trim.iterrows():
    tooltip_text = row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
29/68:
# save the interactive maps as an html file
m.save('art.html')
36/1:
import pandas as pd
import geopandas as gpd
36/2:
# importing my shapefile to this notebook
art = gpd.read_file('data/Civic Art Collection.zip')
36/3:
# importing my shapefile to this notebook
art = gpd.read_file('data/Civic Art Collection.zip')
36/4:
# what's the data type?
type(art)
36/5:
# what exactly does my data look like? 
art.head(3)
36/6: art.dtypes
36/7: art.info()
36/8: art.shape
36/9:
# column name in brackets
# single column
art['medium'].sample(3)
36/10: art['medium'].value_counts()
36/11:
# output the original data's info again
art.info()
36/12:
# now let's create a dataframe with a specific subset of the columns that I identified earlier
art[['artist', 'display_ti', 'medium', 'media_supp', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']]
36/13:
# create and define a list of desired column names
desired_columns = ['artist', 'display_ti', 'medium', 'media_supp', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']

# subset based on desired columns
art[desired_columns].sample(3)
36/14:
art_trim = art[desired_columns].copy()
art_trim
36/15: art_trim.plot()
36/16:
art_trim.plot(
            figsize=(14,12),   # determines the size of the plot 
            column = 'supervisor',   # column that defines the color of the dots
            legend = True,     # adds a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this places the legend on the side
)
36/17: import folium
36/18: import folium
36/19:
# default folium map
m = folium.Map()
m
36/20:
# find the average latitude of the data points first
latitude = art_trim.latitude.mean()
latitude
36/21:
# next we find the average longitude 
longitude = art_trim.longitude.mean()
longitude
36/22:
# centered based on the average lat/lon calculated above
m = folium.Map(location=[37.741717888974996, -122.42401938244218])
m
36/23:
# run a loop through a dataframe:
for index, row in art_trim.iterrows():
    print(row.display_ti, row.latitude, row.longitude)
36/24:
for index, row in art_trim.iterrows():
    # add folium marker code that shows display name of each art piece
    folium.Marker([row.latitude, row.longitude], popup=row.display_ti, tooltip=row.display_ti).add_to(m)
m
36/25:
# lets add a new column dedicated to color
art_trim['color'] = ''
36/26: art_trim.head(3)
36/27:
# find unique values in the supervisor column
art_trim.supervisor.unique()
36/28:
# Add a color value to each of the eleven districts
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
art_trim.loc[art_trim['supervisor'] == '03', 'color'] = 'purple'
art_trim.loc[art_trim['supervisor'] == '04', 'color'] = 'orange'
art_trim.loc[art_trim['supervisor'] == '05', 'color'] = 'beige'
art_trim.loc[art_trim['supervisor'] == '06', 'color'] = 'darkblue'
art_trim.loc[art_trim['supervisor'] == '07', 'color'] = 'cadetblue'
art_trim.loc[art_trim['supervisor'] == '08', 'color'] = 'pink'
art_trim.loc[art_trim['supervisor'] == '09', 'color'] = 'gray'
art_trim.loc[art_trim['supervisor'] == '10', 'color'] = 'lightgreen'
art_trim.loc[art_trim['supervisor'] == '11', 'color'] = 'red'
36/29: art_trim.sample(3)
36/30:
# let's reset the map and get ready to add the color-coded icons
m = folium.Map(location=[latitude,longitude], tiles='CartoDB positron', zoom_start=12)
36/31:
# alright, lets finally add the color-coded and interactive icons
for index, row in art_trim.iterrows():
    tooltip_text = row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
36/32:
# finally, I'll save the interactive maps as an html file
m.save('art.html')
36/33:
# finally, I'll save the interactive maps as an html file
m.save('art.html')
36/34:
# finally, I'll save the interactive maps as an html file
m.save('art.html')
42/1: [interactive maps](https://nbviewer.org/github/rlkovinsky/up221-rachel/blob/main/week02/week%201%20assignment.ipynb)
42/2:
import pandas as pd
import geopandas as gpd
42/3:
# importing my shapefile to this notebook
art = gpd.read_file('data/Civic Art Collection.zip')
42/4:
# what's the data type?
type(art)
42/5:
# what exactly does my data look like? 
art.head(3)
42/6: art.dtypes
42/7: art.info()
42/8: art.shape
42/9:
# column name in brackets
# single column
art['medium'].sample(3)
42/10: art['medium'].value_counts()
42/11:
# output the original data's info again
art.info()
42/12:
# now let's create a dataframe with a specific subset of the columns that I identified earlier
art[['artist', 'display_ti', 'medium', 'media_supp', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']]
42/13:
# create and define a list of desired column names
desired_columns = ['artist', 'display_ti', 'medium', 'media_supp', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']

# subset based on desired columns
art[desired_columns].sample(3)
42/14:
art_trim = art[desired_columns].copy()
art_trim
42/15: art_trim.plot()
42/16:
art_trim.plot(
            figsize=(14,12),   # determines the size of the plot 
            column = 'supervisor',   # column that defines the color of the dots
            legend = True,     # adds a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this places the legend on the side
)
42/17: import folium
42/18:
# default folium map
m = folium.Map()
m
42/19:
# find the average latitude of the data points first
latitude = art_trim.latitude.mean()
latitude
42/20:
# next we find the average longitude 
longitude = art_trim.longitude.mean()
longitude
42/21:
# centered based on the average lat/lon calculated above
m = folium.Map(location=[37.741717888974996, -122.42401938244218])
m
42/22:
# run a loop through a dataframe:
for index, row in art_trim.iterrows():
    print(row.display_ti, row.latitude, row.longitude)
42/23:
for index, row in art_trim.iterrows():
    # add folium marker code that shows display name of each art piece
    folium.Marker([row.latitude, row.longitude], popup=row.display_ti, tooltip=row.display_ti).add_to(m)
m
42/24:
# lets add a new column dedicated to color
art_trim['color'] = ''
42/25: art_trim.head(3)
42/26:
# find unique values in the supervisor column
art_trim.supervisor.unique()
42/27:
# Add a color value to each of the eleven districts
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
art_trim.loc[art_trim['supervisor'] == '03', 'color'] = 'purple'
art_trim.loc[art_trim['supervisor'] == '04', 'color'] = 'orange'
art_trim.loc[art_trim['supervisor'] == '05', 'color'] = 'beige'
art_trim.loc[art_trim['supervisor'] == '06', 'color'] = 'darkblue'
art_trim.loc[art_trim['supervisor'] == '07', 'color'] = 'cadetblue'
art_trim.loc[art_trim['supervisor'] == '08', 'color'] = 'pink'
art_trim.loc[art_trim['supervisor'] == '09', 'color'] = 'gray'
art_trim.loc[art_trim['supervisor'] == '10', 'color'] = 'lightgreen'
art_trim.loc[art_trim['supervisor'] == '11', 'color'] = 'red'
42/28: art_trim.sample(3)
42/29:
# let's reset the map and get ready to add the color-coded icons
m = folium.Map(location=[latitude,longitude], tiles='CartoDB positron', zoom_start=12)
42/30:
# alright, lets finally add the color-coded and interactive icons
for index, row in art_trim.iterrows():
    tooltip_text = row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
42/31:
# finally, I'll save the interactive maps as an html file
m.save('art.html')
42/32:
# importing my shapefile to this notebook
art = gpd.read_file('data/Civic Art Collection.zip')
42/33:
import pandas as pd
import geopandas as gpd
42/34:
# importing my shapefile to this notebook
art = gpd.read_file('data/Civic Art Collection.zip')
42/35:
# what's the data type?
type(art)
42/36:
# what exactly does my data look like? 
art.head(3)
42/37: art.dtypes
42/38: art.info()
42/39: art.shape
42/40:
# column name in brackets
# single column
art['medium'].sample(3)
42/41: art['medium'].value_counts()
42/42:
# output the original data's info again
art.info()
42/43:
# now let's create a dataframe with a specific subset of the columns that I identified earlier
art[['artist', 'display_ti', 'medium', 'media_supp', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']]
42/44:
# create and define a list of desired column names
desired_columns = ['artist', 'display_ti', 'medium', 'media_supp', 'zip_code', 'latitude', 'longitude', 'supervisor', 'geometry']

# subset based on desired columns
art[desired_columns].sample(3)
42/45:
art_trim = art[desired_columns].copy()
art_trim
42/46: art_trim.plot()
42/47:
art_trim.plot(
            figsize=(14,12),   # determines the size of the plot 
            column = 'supervisor',   # column that defines the color of the dots
            legend = True,     # adds a legend           
            legend_kwds={
               'loc': 'upper right',
               'bbox_to_anchor':(1,1)
            }                  # this places the legend on the side
)
42/48: import folium
42/49:
# default folium map
m = folium.Map()
m
42/50:
# find the average latitude of the data points first
latitude = art_trim.latitude.mean()
latitude
42/51:
# next we find the average longitude 
longitude = art_trim.longitude.mean()
longitude
42/52:
# centered based on the average lat/lon calculated above
m = folium.Map(location=[37.741717888974996, -122.42401938244218])
m
42/53:
# run a loop through a dataframe:
for index, row in art_trim.iterrows():
    print(row.display_ti, row.latitude, row.longitude)
42/54:
for index, row in art_trim.iterrows():
    # add folium marker code that shows display name of each art piece
    folium.Marker([row.latitude, row.longitude], popup=row.display_ti, tooltip=row.display_ti).add_to(m)
m
42/55:
# lets add a new column dedicated to color
art_trim['color'] = ''
42/56: art_trim.head(3)
42/57:
# find unique values in the supervisor column
art_trim.supervisor.unique()
42/58:
# Add a color value to each of the eleven districts
art_trim.loc[art_trim['supervisor'] == '01', 'color'] = 'blue'
art_trim.loc[art_trim['supervisor'] == '02', 'color'] = 'green'
art_trim.loc[art_trim['supervisor'] == '03', 'color'] = 'purple'
art_trim.loc[art_trim['supervisor'] == '04', 'color'] = 'orange'
art_trim.loc[art_trim['supervisor'] == '05', 'color'] = 'beige'
art_trim.loc[art_trim['supervisor'] == '06', 'color'] = 'darkblue'
art_trim.loc[art_trim['supervisor'] == '07', 'color'] = 'cadetblue'
art_trim.loc[art_trim['supervisor'] == '08', 'color'] = 'pink'
art_trim.loc[art_trim['supervisor'] == '09', 'color'] = 'gray'
art_trim.loc[art_trim['supervisor'] == '10', 'color'] = 'lightgreen'
art_trim.loc[art_trim['supervisor'] == '11', 'color'] = 'red'
42/59: art_trim.sample(3)
42/60:
# let's reset the map and get ready to add the color-coded icons
m = folium.Map(location=[latitude,longitude], tiles='CartoDB positron', zoom_start=12)
42/61:
# alright, lets finally add the color-coded and interactive icons
for index, row in art_trim.iterrows():
    tooltip_text = row.display_ti
    folium.Marker(
        [row.latitude,row.longitude], 
        popup=row.display_ti, 
        tooltip=tooltip_text,
        icon=folium.Icon(color=row.color)
    ).add_to(m)

# show the map
m
42/62:
# finally, I'll save the interactive maps as an html file
m.save('art.html')
49/1: import pandas as pd
49/2:
# load a data file
# note the relative filepath! where is this file located?
df = pd.read_csv('data/R13280610_SL140.csv')
49/3: df.shape
49/4: df.head()
49/5:
# wont actually show all 50 columns, too much so it will just show 20
df.head()
49/6:
# I want to see all the data
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
49/7:
# I want to see all the data hack
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
49/8: df.sample()
49/9: df.sample()
49/10:
# look at the data types
df.info(verbose=True, show_counts=True)
49/11:
# look at the data types, remember that counting starts at zero
df.info(verbose=True, show_counts=True)
49/12:
# look at the data types, remember that counting starts at zero
df.info(verbose=True, show_counts=True)
49/13: df.Geo_FIPS.head()
49/14: df.Geo_STATE.head()
49/15: df.Geo_COUNTY.head()
49/16:
df = pd.read_csv(
    'data/R13280610_SL140.csv',
    dtype=
    {
        'Geo_FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
49/17:
# now look at the data again
df.head()
49/18: df.info(verbose=True, show_counts=True)
49/19: df.columns[df.isna().all()].tolist()
49/20: df.info()
49/21: df = df.dropna(axis=1,how="all")
49/22: df.info()
49/23:
# reinspect the data
df.head()
49/24:
# define columns to keep
columns_to_keep = ['Geo_FIPS',
                   'SE_T004_019',
                   'SE_T004_001',
                   'SE_T004_003',
                   'SE_T004_005',
                   'SE_T004_007',
                   'SE_T004_009',
                   'SE_T004_011',
                   'SE_T004_013',
                   'SE_T004_015',
                   'SE_T004_017']
# add it to a new dataframe
df2 = df[columns_to_keep]
49/25:
columns = list(df2) # this is the same as df.columns.to_list()
columns
49/26:
# define columns to keep
columns_to_keep = ['Geo_FIPS',
                   'SE_T004_019',
                   'SE_T004_001',
                   'SE_T004_003',
                   'SE_T004_005',
                   'SE_T004_007',
                   'SE_T004_009',
                   'SE_T004_011',
                   'SE_T004_013',
                   'SE_T004_015',
                   'SE_T004_017']
# add it to a new dataframe
df2 = df[columns_to_keep]
49/27:
df2.columns = ['FIPS',
'TotalPop',
'Non Hispanic',
'Non Hispanic White Alone',
'Non Hispanic Black Alone',
'Non Hispanic American Indian and Alaska Native Alone',
'Non Hispanic Asian Alone',
'Non Hispanic Native Hawaiian and Pacific Islander Alone',
'Non Hispanic Other Alone',
'Non Hispanic Multi Race',
'Hispanic']
49/28: df2.sample(5)
49/29:
# access a single column like df['col_name']
df2['TotalPop'].head()
49/30:
# What is the mean?
df2['TotalPop'].mean()
49/31:
# What is the median?
df2['TotalPop'].median()
49/32:
# get some stats
df2['TotalPop'].describe()
49/33:
# get some stats, quick stats summary
df2['TotalPop'].describe()
49/34:
# plot it as a historgram with 50 bins
df2['TotalPop'].plot.hist(bins=50)
49/35:
# box plot: notice the different syntax to generate it
df2.boxplot(column=['TotalPop'])
49/36: df2.plot.scatter(x='Non Hispanic Black Alone',y='Non Hispanic White Alone')
49/37: df_sorted = df2.sort_values(by='TotalPop',ascending = False)
49/38:
# display the data, but just a few columns to keep it clean
df_sorted[['FIPS','TotalPop']].head(10)
49/39:
# plot it
df_sorted.head(10).plot.bar(x='FIPS',
                            y='TotalPop')
49/40:
# Make it prettier with a title
# barh means horizontal
df_sorted.head(10).plot.barh(x='FIPS',
                            y='TotalPop', 
                            title='Top 10 Census Tracts with Highest Population in Los Angeles County in 2020',
                            color='red')
49/41:
# subset the data so that we can see the data per row... 
# in other words, this syntax is asking to "show me the values in my dataframe that match this filter
df2[df2['TotalPop']==0]
49/42:
# create a new variable for census tracts with zero pop
df_no_pop = df2[df2['TotalPop']==0]
49/43:
# how many records?
print('There are ' + str(len(df_no_pop)) + ' census tracts with no people in them')
49/44:
# display it
df_no_pop[['FIPS','TotalPop']]
49/45: import geopandas as gpd
49/46:
# read in a geojson file downloaded from the LA Times
tracts=gpd.read_file('data/Census_Tracts_2020.geojson')
tracts.head()
49/47:
# read in a geojson file downloaded from the LA Times
tracts=gpd.read_file('data/Census_Tracts_2020.geojson')
tracts.head()
49/48:
# plot it!
tracts.plot(figsize=(12,10))
49/49:
# tell me more about this dataset
tracts.info(verbose=True, show_counts=True)
49/50:
# we only really need FIPS and geometry, so let's subset the data
tracts = tracts[['CT20','geometry']]
tracts.head()
49/51:
# create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['CT20']
49/52:
# create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['CT20']
49/53:
# check it!
tracts.head()
49/54:
# create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['CT20']
49/55:
# create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['CT20']
49/56:
# check it!
tracts.head()
49/57:
# tracts is spatial file so that becomes the base, needs to be on the outisde, direction matter
# create a new dataframe based on the join
tracts_race=tracts.merge(df2,on="FIPS")
49/58:
# what does it look like now?
tracts_race.head()
49/59:
tracts_race.plot(figsize=(12,10),
                 column='Non Hispanic Black Alone',
                 legend=True, 
                 scheme='NaturalBreaks')
49/60:
tracts_race.plot(figsize=(12,10),
                 column='Non Hispanic Black Alone',
                 legend=True, 
                 scheme='equal_interval')
49/61:
tracts_race.plot(figsize=(12,10),
                 column='Non Hispanic Black Alone',
                 legend=True, 
                 scheme='quantiles')
49/62:
# First, create new columns for percentages
tracts_race['PCT_Black'] = tracts_race['Non Hispanic Black Alone']/tracts_race['TotalPop']*100
tracts_race['PCT_White'] = tracts_race['Non Hispanic White Alone']/tracts_race['TotalPop']*100
tracts_race['PCT_Asian'] = tracts_race['Non Hispanic Asian Alone']/tracts_race['TotalPop']*100
49/63:
tracts_race.plot(figsize=(12,10),
                 column='PCT_Black',
                 legend=True, 
                 scheme='equal_interval')
49/64: tracts_race.head()
49/65:
tracts_race.plot(figsize=(12,10),
                 column='PCT_White',
                 legend=True, 
                 scheme='equal_interval')
49/66:
tracts_race.plot(figsize=(12,10),
                 column='PCT_Asian',
                 legend=True, 
                 scheme='equal_interval')
49/67: tracts_race[tracts_race.PCT_Black > 50].plot(figsize=(12,10))
49/68: tracts_race[tracts_race.PCT_Black > 50].plot(figsize=(20,10))
49/69: tracts_race[tracts_race.PCT_Black > 50].plot(figsize=(40,10))
49/70: tracts_race[tracts_race.PCT_Black > 50].plot(figsize=(12,40))
49/71: tracts_race[tracts_race.PCT_White > 50].plot(figsize=(12,10))
49/72: tracts_race[tracts_race.PCT_Asian > 50].plot(figsize=(12,10))
49/73:
m = folium.Map(location=[34.2,-118.2], 
               zoom_start = 9,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_race, # geo data
                  data=tracts_race, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'PCT_Black'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Population Black (2020)').add_to(m)    # name on the legend color bar
m
49/74:
m = folium.Map(location=[34.2,-118.2], 
               zoom_start = 9,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_race, # geo data
                  data=tracts_race, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'PCT_Black'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Population Black (2020)').add_to(m)    # name on the legend color bar
m
49/75:
m = folium.Map(location=[34.2,-118.2], 
               zoom_start = 9,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_race, # geo data
                  data=tracts_race, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'PCT_Black'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Population Black (2020)').add_to(m)    # name on the legend color bar
m
49/76: import folium
49/77:
m = folium.Map(location=[34.2,-118.2], 
               zoom_start = 9,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_race, # geo data
                  data=tracts_race, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'PCT_Black'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Population Black (2020)').add_to(m)    # name on the legend color bar
m
49/78:
m = folium.Map(location=[34.2,-118.2], 
               zoom_start = 9,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_race, # geo data
                  data=tracts_race, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'PCT_Black'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Population Black (2020)').add_to(m)    # name on the legend color bar
m
49/79: m.save('LA_Black.html')
51/1: import pandas as pd
51/2:
# load a data file
# note the relative filepath! where is this file located?
df = pd.read_csv('data/R13280610_SL140.csv')
51/3: df.shape
51/4:
# wont actually show all 50 columns, too much so it will just show 20
df.head()
51/5:
# I want to see all the data hack
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
51/6: df.sample()
51/7:
# look at the data types, remember that counting starts at zero
df.info(verbose=True, show_counts=True)
51/8: df.Geo_FIPS.head()
51/9: df.Geo_STATE.head()
51/10:
df = pd.read_csv(
    'data/R13280610_SL140.csv',
    dtype=
    {
        'Geo_FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
51/11:
# now look at the data again
df.head()
51/12: df.info(verbose=True, show_counts=True)
51/13: df.columns[df.isna().all()].tolist()
51/14: df = df.dropna(axis=1,how="all")
51/15: df.info()
51/16:
# reinspect the data
df.head()
51/17:
# define columns to keep
columns_to_keep = ['Geo_FIPS',
                   'SE_T004_019',
                   'SE_T004_001',
                   'SE_T004_003',
                   'SE_T004_005',
                   'SE_T004_007',
                   'SE_T004_009',
                   'SE_T004_011',
                   'SE_T004_013',
                   'SE_T004_015',
                   'SE_T004_017']
# add it to a new dataframe
df2 = df[columns_to_keep]
51/18:
columns = list(df2) # this is the same as df.columns.to_list()
columns
51/19:
df2.columns = ['FIPS',
'TotalPop',
'Non Hispanic',
'Non Hispanic White Alone',
'Non Hispanic Black Alone',
'Non Hispanic American Indian and Alaska Native Alone',
'Non Hispanic Asian Alone',
'Non Hispanic Native Hawaiian and Pacific Islander Alone',
'Non Hispanic Other Alone',
'Non Hispanic Multi Race',
'Hispanic']
51/20: df2.sample(5)
51/21:
# access a single column like df['col_name']
df2['TotalPop'].head()
51/22:
# What is the mean?
df2['TotalPop'].mean()
51/23:
# What is the median?
df2['TotalPop'].median()
51/24:
# get some stats, quick stats summary
df2['TotalPop'].describe()
51/25:
# plot it as a historgram with 50 bins
df2['TotalPop'].plot.hist(bins=50)
51/26:
# box plot: notice the different syntax to generate it
df2.boxplot(column=['TotalPop'])
51/27: df2.plot.scatter(x='Non Hispanic Black Alone',y='Non Hispanic White Alone')
51/28: df_sorted = df2.sort_values(by='TotalPop',ascending = False)
51/29:
# display the data, but just a few columns to keep it clean
df_sorted[['FIPS','TotalPop']].head(10)
51/30:
# plot it
df_sorted.head(10).plot.bar(x='FIPS',
                            y='TotalPop')
51/31:
# Make it prettier with a title
# barh means horizontal
df_sorted.head(10).plot.barh(x='FIPS',
                            y='TotalPop', 
                            title='Top 10 Census Tracts with Highest Population in Los Angeles County in 2020',
                            color='red')
51/32:
# subset the data so that we can see the data per row... 
# in other words, this syntax is asking to "show me the values in my dataframe that match this filter
df2[df2['TotalPop']==0]
51/33:
# create a new variable for census tracts with zero pop
df_no_pop = df2[df2['TotalPop']==0]
51/34:
# how many records?
print('There are ' + str(len(df_no_pop)) + ' census tracts with no people in them')
51/35:
# display it
df_no_pop[['FIPS','TotalPop']]
51/36: df2[df2['Non Hispanic Black Alone']==0]
51/37: df2[df2['Non Hispanic Black Alone']==5000+]
51/38: df2[df2['Non Hispanic Black Alone']==5000>]
51/39: df2[df2['Non Hispanic Black Alone']=>5000]
51/40: df2[df2['Non Hispanic Black Alone']>5000]
51/41: df2[df2['Non Hispanic Black Alone']>=5000]
51/42: df2[df2['Non Hispanic Black Alone']=5000]
51/43: df2[df2['Non Hispanic Black Alone']==5000]
51/44: df2[df2['Non Hispanic Black Alone']>5000]
51/45: df2[df2['Hispanic']>5000]
51/46:
df2[df2['Hispanic']>5000]
df_hispanic5k = df2[df2['Hispanic']>5000]
df_hispanic5k[['FIPS','TotalPop']]
51/47:
df2[df2['Hispanic']>5000]
df_hispanic5k = df2[df2['Hispanic']>5000]
df_hispanic5k[['FIPS','Hispanic']]
51/48:
df2[df2['Hispanic']>5000]
df_hispanic5k = df2[df2['Hispanic']>5000]
df_hispanic5k[['FIPS','Hispanic']]
df_sorted = df_hispanic5k.sort_values(by='Hispanic',ascending = False)
df_sorted[['FIPS','Hispanic']].head(5)
51/49: import geopandas as gpd
51/50:
# read in a geojson file downloaded from the LA Times
tracts=gpd.read_file('data/Census_Tracts_2020.geojson')
tracts.head()
51/51:
# read in a geojson file downloaded from the LA Times
tracts=gpd.read_file('data/Census_Tracts_2020.geojson')
tracts.head()
51/52:
# plot it!
tracts.plot(figsize=(12,10))
51/53:
# plot it!
tracts.plot(figsize=(12,10))
51/54:
# tell me more about this dataset
tracts.info(verbose=True, show_counts=True)
51/55:
# we only really need FIPS and geometry, so let's subset the data
tracts = tracts[['CT20','geometry']]
tracts.head()
51/56:
# create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['CT20']
51/57:
# create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['CT20']
51/58:
# check it!
tracts.head()
51/59:
# tracts is spatial file so that becomes the base, needs to be on the outisde, direction matter
# create a new dataframe based on the join
tracts_race=tracts.merge(df2,on="FIPS")
51/60:
# what does it look like now?
tracts_race.head()
51/61:
tracts_race.plot(figsize=(12,10),
                 column='Non Hispanic Black Alone',
                 legend=True, 
                 scheme='NaturalBreaks')
51/62:
tracts_race.plot(figsize=(12,10),
                 column='Non Hispanic Black Alone',
                 legend=True, 
                 scheme='equal_interval')
51/63:
tracts_race.plot(figsize=(12,10),
                 column='Non Hispanic Black Alone',
                 legend=True, 
                 scheme='quantiles')
51/64:
# First, create new columns for percentages
tracts_race['PCT_Black'] = tracts_race['Non Hispanic Black Alone']/tracts_race['TotalPop']*100
tracts_race['PCT_White'] = tracts_race['Non Hispanic White Alone']/tracts_race['TotalPop']*100
tracts_race['PCT_Asian'] = tracts_race['Non Hispanic Asian Alone']/tracts_race['TotalPop']*100
51/65: tracts_race.head()
51/66:
tracts_race.plot(figsize=(12,10),
                 column='PCT_Black',
                 legend=True, 
                 scheme='equal_interval')
51/67:
tracts_race.plot(figsize=(12,10),
                 column='PCT_White',
                 legend=True, 
                 scheme='equal_interval')
51/68:
tracts_race.plot(figsize=(12,10),
                 column='PCT_Asian',
                 legend=True, 
                 scheme='equal_interval')
51/69: tracts_race[tracts_race.PCT_Black > 50].plot(figsize=(12,40))
51/70: tracts_race[tracts_race.PCT_White > 50].plot(figsize=(12,10))
51/71: import folium
51/72:
m = folium.Map(location=[34.2,-118.2], 
               zoom_start = 9,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_race, # geo data
                  data=tracts_race, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'PCT_Black'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Population Black (2020)').add_to(m)    # name on the legend color bar
m
53/1: import pandas as pd
53/2:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/3: cd.shap
53/4: cd.shape
53/5: cd.head(3)
53/6: cd.info()
53/7: cd.FIPS.head(5)
53/8: cd.Geo.State.head(3)
53/9: cd.Geo.state.head(3)
53/10: cd.Geo_STATE.head(3)
53/11: cd.Geo_COUNTY.head(3)
53/12:
#re-import data
# make FIPS column a string 

cd = pd.read_csv(
    'data/SFMedianIncome.csv',
    dtype=
    {
        'FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
53/13:
# double check this worked
cd.head(3)
53/14:
#re-import data
# make FIPS column a string 

cd = pd.read_csv(
    'data/SFMedianIncome.csv',
    dtype=
    {
        'FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
53/15:
# double check this worked
cd.head(3)
53/16: import pandas as pd
53/17:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/18: cd.shape
53/19: cd.head(3)
53/20: cd.info()
53/21: cd.FIPS.head(5)
53/22:
#re-import data
# make FIPS column a string 

cd = pd.read_csv(
    'data/SFMedianIncome.csv',
    dtype=
    {
        'FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
53/23:
# double check this worked
cd.head(3)
53/24:
# double check this worked
cd.head(3)
52/1: import pandas as pd
52/2:
# load a data file
# note the relative filepath! where is this file located?
df = pd.read_csv('data/R13280610_SL140.csv')
52/3:
# wont actually show all 50 columns, too much so it will just show 20
df.head()
52/4: df.sample()
52/5: df.Geo_FIPS.head()
52/6: df.Geo_STATE.head()
52/7: df.Geo_COUNTY.head()
52/8:
df = pd.read_csv(
    'data/R13280610_SL140.csv',
    dtype=
    {
        'Geo_FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
52/9:
# now look at the data again
df.head()
53/25:
#re-import data
# make FIPS column a string 

cd = pd.read_csv(
    'data/SFMedianIncome.csv',
    dtype=
    {
        'FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
53/26:
# double check this worked
cd.head(3)
53/27: import pandas as pd
53/28:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/29: cd.shape
53/30: cd.head(3)
53/31: cd.info()
53/32:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/33: cd.shape
53/34: cd.head(3)
53/35: import pandas as pd
53/36:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/37: cd.shape
53/38: cd.head(3)
53/39: cd.head(3)
53/40: cd.info()
53/41: cd.FIPS.head(5)
53/42:
#re-import data
# make FIPS column a string 

cd = pd.read_csv(
    'data/SFMedianIncome.csv',
    dtype=
    {
        'FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
53/43:
# double check this worked
cd.head(3)
53/44: cd.info()
53/45: cd.columns[cd.isna().all()].tolist()
53/46: cd = cd.dropna(axis=1,how="all")
53/47: cd.info()
53/48:
# double checking that column was dropped correctly
cd.info()
53/49: ## Deciding Which Columns to Keep
53/50: import pandas as pd
53/51:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/52: cd.shape
53/53: cd.head(3)
53/54: cd.info()
53/55: cd.FIPS.head(5)
53/56:
#re-import data
# make FIPS column a string 

cd = pd.read_csv(
    'data/SFMedianIncome.csv',
    dtype=
    {
        'FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
53/57:
# double check this worked
cd.head(3)
53/58: cd.info()
53/59: cd.columns[cd.isna().all()].tolist()
53/60: cd = cd.dropna(axis=1,how="all")
53/61:
# double checking that column was dropped correctly
cd.info()
53/62:
# define columns to keep
columns_to_keep = ['FIPS',
                   'Median Household Income']
# add it to a new dataframe!
cd2 = cd[columns_to_keep]
53/63: cd2.info()
53/64: cd2.head(3)
53/65: cd2.sample(4)
53/66: #df2['Median Household Income'].mean()
53/67: #df2['MedianHouseholdIncome'].mean()
53/68: df2['MedianHouseholdIncome'].mean()
53/69: df2['Median Household Income'].mean()
53/70: cd2['Median Household Income'].mean()
53/71: cd2['Median Household Income'].median()
53/72:
# get a quick stats summary
cd2['Median Household Income'].describe()
53/73:
# plot it as a historgram with 10 bins
cd2['Median Household Income'].plot.hist(bins=10)
53/74:
# now, a box plot
cd2.boxplot(column=['Median Household Income'])
53/75: cd_sorted = cd2.sort_values(by='Median Household Income',ascending = False)
53/76:
# lets display the data, but just a few of the columns to get a sense for the top 5 highest median household income census tracts
df_sorted[['FIPS','Median Household Income']].head(5)
53/77:
# lets display the data, but just a few of the columns to get a sense for the top 5 highest median household income census tracts
cd_sorted[['FIPS','Median Household Income']].head(5)
53/78:
# lets see if I can get the five lowest median household income tracts to show now
cd_sorted = cd2.sort_values(by='Median Household Income',ascending = True)
cd_sorted[['FIPS','Median Household Income']].head(5)
53/79:
# plot it
cd_sorted.head(5).plot.bar(x='FIPS',
                            y='Median Household Income')
53/80:
# make it look a bit better 
cd_sorted.head(5).plot.barh(x='FIPS',
                            y='MedianHouseholdIncome', 
                            title='5 Census Tracts with the Lowest Household Median Income in SF 2021',
                            color='red')
52/10:
# Make it prettier with a title
# barh means horizontal
df_sorted.head(10).plot.barh(x='FIPS',
                            y='TotalPop', 
                            title='Top 10 Census Tracts with Highest Population in Los Angeles County in 2020',
                            color='red')
52/11:
# Make it prettier with a title
# barh means horizontal
df_sorted.head(10).plot.barh(x='FIPS',
                            y='TotalPop', 
                            title='Top 10 Census Tracts with Highest Population in Los Angeles County in 2020',
                            color='red')
52/12:
# plot it
df_sorted.head(10).plot.bar(x='FIPS',
                            y='TotalPop')
52/13: df_sorted = df2.sort_values(by='TotalPop',ascending = False)
53/81:
# make it look a bit better 
cd_sorted.head(5).plot.barh(x='FIPS',
                            y='Median Household Income', 
                            title='5 Census Tracts with the Lowest Household Median Income in SF 2021',
                            color='red')
53/82:
# make it look a bit better 
cd_sorted.head(5).plot.barh(x='FIPS',
                            y='Median Household Income', 
                            title='5 Census Tracts with the Lowest Household Median Income in SF 2021',
                            color='orange')
53/83:
# make the bar chart look a bit better 
cd_sorted.head(5).plot.barh(x='FIPS',
                            y='Median Household Income', 
                            title='5 Census Tracts with the Lowest Household Median Income in SF 2021',
                            color='orange')
53/84: cd2[cd2['Median Household Income']>100000]
53/85: cd2[cd2['Median Household Income']<50000]
53/86: import geopandas as gpd
53/87:
# read in a geojson file
tracts=gpd.read_file('data/2020CensusTracts_SF.geojson')
tracts.head()
53/88:
# read in a geojson file
tracts=gpd.read_file('data/2020CensusTracts_SF.geojson')
tracts.head()
53/89:
# plot it!
tracts.plot(figsize=(12,10))
53/90: import geopandas as gpd
53/91:
# read in a geojson file
tracts=gpd.read_file('data/2020CensusTracts_SF.geojson')
tracts.head()
53/92:
# plot it!
tracts.plot(figsize=(12,10))
53/93:
# read in a geojson file
tracts=gpd.read_file('data/2020CensusTracts_SF.geojson')
tracts.head()
53/94:
# read in a geojson file
tracts=gpd.read_file('data/2020SFCTs.geojson')
tracts.head()
53/95:
# plot it!
tracts.plot(figsize=(12,10))
53/96:
# tell me more about this dataset
tracts.info(verbose=True, show_counts=True)
53/97:
# I only really need FIPS and geometry, so let's subset the data
tracts = tracts[['tractce','geometry']]
tracts.head()
53/98:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
tracts.head()
53/99:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
tracts.head()
53/100:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd2,on="FIPS")
53/101: tracts_income.head(4)
53/102:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
tracts.head()
53/103:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
53/104: tracts.head()
53/105:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd2,on="FIPS")
53/106: tracts_income.head(4)
53/107: tracts_income.head()
52/14:
# create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['CT20']
53/108: import geopandas as gpd
53/109:
# read in a geojson file
tracts=gpd.read_file('data/2020SFCTs.geojson')
tracts.head()
53/110:
# plot it!
tracts.plot(figsize=(12,10))
53/111:
# tell me more about this dataset
tracts.info(verbose=True, show_counts=True)
53/112:
# I only really need FIPS and geometry, so let's subset the data
tracts = tracts[['tractce','geometry']]
tracts.head()
53/113:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
53/114:
# now I create a FIPS column
tracts['FIPS'] =''06' + '037' + tracts['tractce']'
53/115:
# now I create a FIPS column
tracts['FIPS'] =''0o6' + '0o37' + tracts['tractce']'
53/116:
# now I create a FIPS column
tracts['FIPS'] =''06' + '037' + tracts['tractce']'
53/117:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
53/118: tracts.head()
53/119:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd2,on="FIPS")
53/120: tracts_income.head()
53/121:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
53/122:
# I only really need FIPS and geometry, so let's subset the data
tractssimp = tracts[['tractce','geometry']]
tractssimp.head()
53/123:
# now I create a FIPS column
tractssimp['FIPS'] ='06' + '037' + tracts['tractce']
53/124: tractssimp.head()
53/125:
# create a new dataframe based on the join
tracts_income=tractssimp.merge(cd2,on="FIPS")
53/126: tracts_income.head()
53/127:
# I only really need FIPS and geometry, so let's subset the data
tractssimp = tracts[['tractce','geometry']]
tractssimp
53/128: tractssimp.head(3)
53/129: import pandas as pd
53/130:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/131: cd.shape
53/132: cd.head(3)
53/133: cd.info()
53/134: cd.FIPS.head(5)
53/135:
#re-import data
# make FIPS column a string 

cd = pd.read_csv(
    'data/SFMedianIncome.csv',
    dtype=
    {
        'FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
53/136:
# double check this worked
cd.head(3)
53/137: cd.info()
53/138: cd.columns[cd.isna().all()].tolist()
53/139: cd = cd.dropna(axis=1,how="all")
53/140:
# double checking that column was dropped correctly
cd.info()
53/141:
# define columns to keep
columns_to_keep = ['FIPS',
                   'Median Household Income']
# add it to a new dataframe!
cd2 = cd[columns_to_keep]
53/142: cd2.sample(4)
53/143: cd_sorted = cd2.sort_values(by='Median Household Income',ascending = False)
53/144:
# lets see if I can get the five lowest median household income tracts to show now
cd_sorted = cd2.sort_values(by='Median Household Income',ascending = True)
cd_sorted[['FIPS','Median Household Income']].head(5)
53/145:
# plot it
cd_sorted.head(5).plot.bar(x='FIPS',
                            y='Median Household Income')
53/146: import geopandas as gpd
53/147:
# read in a geojson file
tracts=gpd.read_file('data/2020SFCTs.geojson')
tracts.head()
53/148:
# plot it!
tracts.plot(figsize=(12,10))
53/149:
# tell me more about this dataset
tracts.info(verbose=True, show_counts=True)
53/150:
# I only really need FIPS and geometry, so let's subset the data
tractssimp = tracts[['tractce','geometry']]
tractssimp
53/151: tractssimp.head(3)
53/152:
# now I create a FIPS column
tractssimp['FIPS'] ='06' + '037' + tracts['tractce']
53/153: tractssimp.head()
53/154:
# create a new dataframe based on the join
tracts_income=tractssimp.merge(cd2,on="FIPS")
53/155: tracts_income.head()
53/156:
tracts_race.plot(figsize=(12,10),
                 column='Median Household Income',
                 legend=True, 
                 scheme='NaturalBreaks')
53/157:
tracts_income.plot(figsize=(12,10),
                 column='Median Household Income',
                 legend=True, 
                 scheme='NaturalBreaks')
53/158: import pandas as pd
53/159:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/160:
# now I create a FIPS column
tractssimp.loc['FIPS','06' + '037' + tracts['tractce']]
53/161:
# I only really need FIPS and geometry, so let's subset the data
tracts = tracts[['tractce','geometry']]
tracts
53/162: tracts.head(3)
53/163:
# now I create a FIPS column
tracts.loc[tracts['FIPS'] == '06' + '037' + tracts['tractce']
53/164:
# now I create a FIPS column
tracts.loc[tracts['FIPS'] == '06' + '037' + tracts['tractce']]
53/165:
# now I create a FIPS column
tracts.loc[tracts['FIPS'] == '06' + '037' + 'tractce']
53/166:
# now I create a FIPS column
tracts.['FIPS'] = '06' + '037' + tracts['tractce']
53/167:
# now I create a FIPS column
tracts['FIPS'] = '06' + '037' + tracts['tractce']
53/168:
# now I create a FIPS column
tracts['FIPS'] = '06' + '037' + 'tractce'
53/169: tractssimp.head()
53/170:
# now I create a FIPS column
tracts['FIPS'] = '06' + '037' + 'tractce'
53/171: tracts.head()
53/172:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd2,on="FIPS")
53/173: tracts_income.head()
53/174: tracts_is_view
53/175: _is_view
53/176:
# now I create a FIPS column
tracts['FIPS'] = '06' + '037' + tracts['tractce']._is_view
53/177:
# now I create a FIPS column
tracts['FIPS'] = '06' + '037' + tracts['tractce']._is_copy
53/178:
# now I create a FIPS column
tracts.loc['FIPS'] = '06' + '037' + tracts['tractce']
tracts[tracts.FIPS]
53/179:
# now I create a FIPS column
tracts.loc['FIPS'] = '06' + '037' + tracts['tractce']
53/180: tracts.head()
53/181:
# now I create a FIPS column
tracts['FIPS'] = '06' + '037' + tracts['tractce']
53/182: tracts.head()
53/183: import pandas as pd
53/184:
# load the data
cd = pd.read_csv('data/SFMedianIncome.csv')
53/185: cd.shape
53/186: cd.head(3)
53/187: cd.info()
53/188: cd.FIPS.head(5)
53/189:
#re-import data
# make FIPS column a string 

cd = pd.read_csv(
    'data/SFMedianIncome.csv',
    dtype=
    {
        'FIPS':str,
        'Geo_STATE':str,
        'Geo_COUNTY': str
    }
)
53/190:
# double check this worked
cd.head(3)
53/191: cd.info()
53/192: cd.columns[cd.isna().all()].tolist()
53/193: cd = cd.dropna(axis=1,how="all")
52/15: df = df.dropna(axis=1,how="all")
53/194:
# double checking that column was dropped correctly
cd.info()
53/195:
# define columns to keep
columns_to_keep = ['FIPS',
                   'Median Household Income']
# add it to a new dataframe!
cd2 = cd[columns_to_keep]
53/196: cd2.sample(4)
53/197: cd2['Median Household Income'].mean()
53/198: cd2['Median Household Income'].median()
53/199:
# get a quick stats summary
cd2['Median Household Income'].describe()
53/200: cd_sorted = cd2.sort_values(by='Median Household Income',ascending = False)
53/201:
# lets display the data, but just a few of the columns to get a sense for the top 5 highest median household income census tracts
cd_sorted[['FIPS','Median Household Income']].head(5)
53/202:
# lets see if I can get the five lowest median household income tracts to show now
cd_sorted = cd2.sort_values(by='Median Household Income',ascending = True)
cd_sorted[['FIPS','Median Household Income']].head(5)
53/203: import geopandas as gpd
53/204:
# read in a geojson file
tracts=gpd.read_file('data/2020SFCTs.geojson')
tracts.head()
53/205:
# tell me more about this dataset
tracts.info(verbose=True, show_counts=True)
53/206:
# I only really need FIPS and geometry, so let's subset the data
tracts = tracts[['tractce','geometry']]
tracts.head()
53/207:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
53/208: tracts.head()
53/209:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd2,on="FIPS")
53/210: tracts_income.head(3)
53/211:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd,on="FIPS")
53/212: tracts_income.head(3)
53/213:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
53/214:
# I only really need FIPS and geometry, so let's subset the data
tracts = tracts[['tractce','geometry']]
tracts.head()
53/215:
# now I create a FIPS column
tracts['FIPS'] ='06' + '037' + tracts['tractce']
53/216: tracts.head()
53/217:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd2,on="FIPS")
53/218: tracts_income.head(3)
53/219: tracts.types()
53/220: tracts.dtypes()
53/221: tracts.head()
53/222: tracts.dtypes
53/223: tracts_income = pandas.DataFrame.merge(tracts, cd2, how='left', on='FIPS')
53/224:
import geopandas as gpd
import pandas as pd
53/225: tracts_income = pandas.DataFrame.merge(tracts, cd2, how='left', on='FIPS')
53/226: tracts_income = pandas.DataFrame.merge(tracts, cd2, how='left', on='FIPS')
53/227: tracts_income = DataFrame.merge(tracts, cd2, how='left', on='FIPS')
53/228: tracts_income = merge(tracts, cd2, how='left', on='FIPS')
53/229: tracts['FIPS].astype(int)
53/230: tracts['FIPS'].astype(int)
53/231: cd2['FIPS'].astype(int)
53/232:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd2,on="FIPS")
53/233: tracts_income.head(3)
53/234:
# now I create a FIPS column
tracts['FIPS'] ='06' + '075' + tracts['tractce']
53/235: tracts.head()
53/236:
# create a new dataframe based on the join
tracts_income=tracts.merge(cd2,on="FIPS")
53/237: tracts_income.head(3)
53/238:
tracts_race.plot(figsize=(12,10),
                 column='Median Household Income',
                 legend=True, 
                 scheme='NaturalBreaks')
53/239:
tracts_income.plot(figsize=(12,10),
                 column='Median Household Income',
                 legend=True, 
                 scheme='NaturalBreaks')
53/240:
#generate a choropleth map based on the merged dataset 
tracts_income.plot(figsize=(12,10),
                 column='Median Household Income',
                 legend=True, 
                 scheme='equal_interval')
53/241:
#generate a choropleth map based on the merged dataset 
tracts_income.plot(figsize=(12,10),
                 column='Median Household Income',
                 legend=True, 
                 scheme='NaturalBreaks')
53/242: import folium
53/243:
m = folium.Map(location=[37.7,-122.4], 
               zoom_start = 9,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_income, # geo data
                  data=tracts_income, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'Median Household Income'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Median Household Income (2020)').add_to(m)    # name on the legend color bar
m
53/244:
m = folium.Map(location=[37.7,-122.4], 
               zoom_start = 12,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_income, # geo data
                  data=tracts_income, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'Median Household Income'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Median Household Income (2020)').add_to(m)    # name on the legend color bar
m
53/245:
m = folium.Map(location=[37.7,-122.4], 
               zoom_start = 11,
               tiles='CartoDB positron', 
               attribution='CartoDB')

# plot chorpleth over the base map
folium.Choropleth(
                  geo_data=tracts_income, # geo data
                  data=tracts_income, # data          
                  key_on='feature.properties.FIPS', # key, or merge column
                  columns=['FIPS', 'Median Household Income'], # [key, value]
                  fill_color='BuPu',
                  line_weight=0.1, 
                  fill_opacity=0.8,
                  line_opacity=0.2, # line opacity (of the border)
                  legend_name='Median Household Income (2020)').add_to(m)    # name on the legend color bar
m
   1: %history -g -f R.Kovinsky_SFIncome.ipynb
